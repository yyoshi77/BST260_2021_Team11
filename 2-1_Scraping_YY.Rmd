---
title: "Scraping Part"
author: "Yusuke Yoshikawa (BST260 Group11)"
output: html_document
---


## Data Collection Part

### Brief sumamry of scraping
First, I collected the tables of marathon records at 4 Olympic marathon game. I further scraped the dates of birth of all athletes by accessing their individual pages. Scraping process was similar across the 4 games, so please see the descriptions at Men Tokyo2020 scraping for data collection of the Olympic games. Then, I combined the 4 datasets into one dataframe. Second, I collected data regarding lockdown policy, COVID-19 cases, populations, financial and geographic data of area/countries which athletes are from. Finally, I saved the dataset as a csv file for subsequent analyses by other members. There are explanations of the columns at the end of this section.

```{r, message=FALSE, warning=FALSE}
#### Libraries ####
library(tidyverse)
library(rvest)
library(lubridate)
#if (!require(RCurl)) {install.packages("RCurl", dependencies=TRUE)}
#library(RCurl)
```

```{r, message=FALSE, warning=FALSE}
#### Men at Tokyo 2020 ####
# URL of Men at Tokyo2020
url_20m <- "https://en.wikipedia.org/wiki/Athletics_at_the_2020_Summer_Olympics_%E2%80%93_Men%27s_marathon"

# Extract all tables in the page
tab <- read_html(url_20m) %>% 
  html_nodes("table") 
# Table of interest
dat_20m <- tab[[8]] %>% 
  html_table() 

# Data reshaping
colnames(dat_20m)[1:4] <- c("rank", "athlete", "country", "time")
dat_20m$rank[1:3] <- c(1:3)
dat_20m <- dat_20m %>% 
  mutate(rank = ifelse(rank=="—", NA, rank)) %>% 
  mutate(sb = ifelse(is.na(rank), NA, 0)) %>% 
  # sb = season best including "national record" and "personal best"
  mutate(sb = ifelse(Notes %in% c("SB","NR","PB"), 1, sb)) %>% 
  # dnf = did not finish including "did not start" and "disqualified"
  mutate(dnf = ifelse(Notes %in% c("DNF","DNS","DSQ"), 1, 0)) %>% 
  mutate(time = lubridate::hms(time)) %>% 
  select(rank, athlete, country, time, sb, dnf)

# Age data collection
urls <- read_html(url_20m) %>% 
  html_nodes("table") %>% 
  .[[8]] %>% 
  # extract all wiki URLs
  html_nodes("a[href *= '/wiki/' ]") %>% 
  html_attr("href") %>% 
  # extracted only URLs including althlete's personal pages
  .[!str_detect(.,"Olympics") & !str_detect(., "Bests") & !str_detect(., "conditions") & !str_detect(., "records")] %>%
  # save the URLs as character vectors
  paste("https://en.wikipedia.org", ., sep="")

# Extraction of Wiki text function
text_detect <- function(url){
  read_html(url) %>% 
    html_nodes("body") %>% 
    .[[1]] %>% 
    html_text()
}
# Application the function to all athletes at the Olympic game
wiki_text <- sapply(urls, text_detect)

# DOB detecting function by string processing
dob_detect <- function(string){
  string %>% str_extract(
  "(born \\d{1,2} (January|February|March|April|May|June|July|August|September|October|November|December).\\d{4})|(born (January|February|March|April|May|June|July|August|September|October|November|December) \\d{1,2}. \\d{4})"
  )
}
# Application the function to all athletes at the Olympic game
dobs <- sapply(wiki_text, dob_detect) %>% 
  as.character() %>% 
  str_replace("born ", "")
dobs_d <- dobs %>% str_extract("\\d{1,2}")
dobs_m <- dobs %>% str_extract("(January|February|March|April|May|June|July|August|September|October|November|December)")
dobs_y <- dobs %>% str_extract("\\d{4}")
dobs <- paste(dobs_y, dobs_m, dobs_d, sep="-") %>% ymd()
dat_20m$dob <- dobs

# Calculate age at the Olympic game
if (!require(eeptools)) {install.packages("eeptools", dependencies=TRUE)}
library(eeptools)
dat_20m <- dat_20m %>% 
  mutate(age = eeptools::age_calc(dob, ymd("2021-08-08"), units = "years") %>% floor)

# Add sex category 
dat_20m$sex <- "Men"
# Add game label
dat_20m$olympic <- "Tokyo2020"

```

```{r, message=FALSE, warning=FALSE}
#### Women at Tokyo 2020 ####
# URL of Women at Tokyo 2020
url_20w <- "https://en.wikipedia.org/wiki/Athletics_at_the_2020_Summer_Olympics_%E2%80%93_Women%27s_marathon"

# Extract all tables in the page
tab <- read_html(url_20w) %>% 
  html_nodes("table") 
# Table of interest
dat_20w <- tab[[8]] %>% 
  html_table()

# Data reshaping
colnames(dat_20w)[1:4] <- c("rank", "athlete", "country", "time")
dat_20w$rank[1:3] <- c(1:3)
dat_20w <- dat_20w %>% 
  mutate(rank = ifelse(rank=="–", NA, rank)) %>% 
  mutate(sb = ifelse(is.na(rank), NA, 0)) %>% 
  mutate(sb = ifelse(Notes %in% c("SB","NR","PB"), 1, sb)) %>% 
  mutate(dnf = ifelse(Notes %in% c("DNF","DNS","DSQ"), 1, 0)) %>% 
  mutate(time = lubridate::hms(time)) %>% 
  select(rank, athlete, country, time, sb, dnf)

# Age data collection
urls <- read_html(url_20w) %>% 
  html_nodes("table") %>% 
  .[[8]] %>% 
  html_nodes("a[href *= '/wiki/' ]") %>% # extract the individual athletes' wikis
  html_attr("href") %>% 
  .[!str_detect(.,"Olympics") & !str_detect(., "Bests") & !str_detect(., "conditions") & !str_detect(., "records")] %>%
  paste("https://en.wikipedia.org", ., sep="")

# Extraction of Wiki text by the function above
wiki_text <- sapply(urls, text_detect)

# DOB detection by string processing
dobs <- sapply(wiki_text, dob_detect) %>% 
  as.character() %>% 
  str_replace("born ", "")
dobs_d <- dobs %>% str_extract("\\d{1,2}")
dobs_m <- dobs %>% str_extract("(January|February|March|April|May|June|July|August|September|October|November|December)")
dobs_y <- dobs %>% str_extract("\\d{4}")
dobs <- paste(dobs_y, dobs_m, dobs_d, sep="-") %>% ymd()
dat_20w$dob <- dobs

# Calculate age at Tokyo 2020
dat_20w <- dat_20w %>% 
  mutate(age = eeptools::age_calc(dob, ymd("2021-08-07"), units = "years") %>% floor)

# Sex category 
dat_20w$sex <- "Women"
# Game label
dat_20w$olympic <- "Tokyo2020"

```

```{r, message=FALSE, warning=FALSE}
#### Men at Rio 2016 ####
# URL of Men at Rio 2016
url_16m <- "https://en.wikipedia.org/wiki/Athletics_at_the_2016_Summer_Olympics_%E2%80%93_Men%27s_marathon"

# Extract all tables in the page
tab <- read_html(url_16m) %>% 
  html_nodes("table") 
# Table of interest
dat_16m <- tab[[6]] %>% 
  html_table() 

# Data reshaping
colnames(dat_16m)[1:4] <- c("rank", "athlete", "country", "time")
dat_16m$rank[1:3] <- c(1:3)
dat_16m <- dat_16m %>% 
  mutate(rank = ifelse(rank=="—", NA, rank)) %>% 
  mutate(sb = ifelse(is.na(rank), NA, 0)) %>% 
  mutate(sb = ifelse(Notes %in% c("SB","NR","PB"), 1, sb)) %>% 
  mutate(dnf = ifelse(time=="DNF" | Notes %in% c("DNF","DNS","DSQ"), 1, 0)) %>% 
  mutate(time = ifelse(dnf==1, NA, time)) %>% 
  mutate(time = lubridate::hms(time)) %>% 
  select(rank, athlete, country, time, sb, dnf)

# Age data collection
urls <- read_html(url_16m) %>% 
  html_nodes("table") %>% 
  .[[6]] %>% 
  html_nodes("a[href *= '/wiki/' ]") %>% # extract the individual athletes' wikis
  html_attr("href") %>% 
  .[!str_detect(.,"Olympics") & !str_detect(., "Bests") & !str_detect(., "conditions") & !str_detect(., "records")] %>%
  paste("https://en.wikipedia.org", ., sep="")

# Extraction of Wiki text
wiki_text <- sapply(urls, text_detect)

# DOB detection by string processing
dobs <- sapply(wiki_text, dob_detect) %>% 
  as.character() %>% 
  str_replace("born ", "")
dobs_d <- dobs %>% str_extract("\\d{1,2}")
dobs_m <- dobs %>% str_extract("(January|February|March|April|May|June|July|August|September|October|November|December)")
dobs_y <- dobs %>% str_extract("\\d{4}")
dobs <- paste(dobs_y, dobs_m, dobs_d, sep="-") %>% ymd()
dat_16m$dob <- dobs

# Calculate age at Rio 2016
dat_16m <- dat_16m %>% 
  mutate(age = eeptools::age_calc(dob, ymd("2016-08-21"), units = "years") %>% floor)

# Sex category 
dat_16m$sex <- "Men"
# Game label
dat_16m$olympic <- "Rio2016"

```

```{r, message=FALSE, warning=FALSE}
#### Women at Rio 2016 ####
# URL of Women at Rio 2016
url_16w <- "https://en.wikipedia.org/wiki/Athletics_at_the_2016_Summer_Olympics_%E2%80%93_Women%27s_marathon"

# Extract all tables in the page
tab <- read_html(url_16w) %>% 
  html_nodes("table") 
# Table of interest
dat_16w <- tab[[6]] %>% 
  html_table() 

# Data reshaping
colnames(dat_16w)[1:4] <- c("rank", "athlete", "country", "time")
dat_16w$rank[1:3] <- c(1:3)
dat_16w <- dat_16w %>% 
  mutate(rank = ifelse(rank=="—", NA, rank)) %>% 
  mutate(sb = ifelse(is.na(rank), NA, 0)) %>% 
  mutate(sb = ifelse(Notes %in% c("SB","NR","PB"), 1, sb)) %>% 
  mutate(dnf = ifelse(time=="DNF" | Notes %in% c("DNF","DNS","DSQ"), 1, 0)) %>% 
  mutate(time = ifelse(dnf==1, NA, time)) %>% 
  mutate(time = lubridate::hms(time)) %>% 
  select(rank, athlete, country, time, sb, dnf)

# Age data collection
urls <- read_html(url_16w) %>% 
  html_nodes("table") %>% 
  .[[6]] %>% 
  html_nodes("a[href *= '/wiki/' ]") %>% # extract the individual athletes' wikis
  html_attr("href") %>% 
  .[!str_detect(.,"Olympics") & !str_detect(., "Bests") & !str_detect(., "conditions") & !str_detect(., "records")] %>%
  paste("https://en.wikipedia.org", ., sep="")

# Extraction of Wiki text
wiki_text <- sapply(urls, text_detect)

# DOB detection by string processing
dobs <- sapply(wiki_text, dob_detect) %>% 
  as.character() %>% 
  str_replace("born ", "")
dobs_d <- dobs %>% str_extract("\\d{1,2}")
dobs_m <- dobs %>% str_extract("(January|February|March|April|May|June|July|August|September|October|November|December)")
dobs_y <- dobs %>% str_extract("\\d{4}")
dobs <- paste(dobs_y, dobs_m, dobs_d, sep="-") %>% ymd()
dobs[128] <- "1980-10-12" %>% ymd()   # missing data (source: https://en.wikipedia.org/wiki/Graciete_Santana)
dat_16w$dob <- dobs

# Calculate age at Rio 2016
dat_16w <- dat_16w %>% 
  mutate(age = eeptools::age_calc(dob, ymd("2016-08-14"), units = "years") %>% floor)

# Sex category 
dat_16w$sex <- "Women"
# Game label
dat_16w$olympic <- "Rio2016"

```

```{r, message=FALSE, warning=FALSE}
#### Combine the 4 dataframes ####
dat <- rbind(dat_20m, dat_20w, dat_16m, dat_16w)

#### Rename the areas/countries ####
dat <- dat %>% 
  mutate(country = ifelse(country=="Chinese Taipei", "Taiwan", country)) %>% 
  mutate(country = ifelse(country=="Democratic Republic of the Congo", "Congo (Kinshasa)", country))

```

```{r, message=FALSE, warning=FALSE}
#### Lockdown area/countries ####
# Source: https://en.m.wikipedia.org/wiki/COVID-19_lockdowns
non_lockdown <- c("Burundi", "Iceland", "Japan", "Nicaragua",
                  "South Korea", "Sweden", "Taiwan", "Tanzania", "Uruguay")
dat <- dat %>% 
  mutate(lockdown = ifelse(country %in% non_lockdown, 0, 1))
```

```{r, message=FALSE, warning=FALSE}
#### Attendance before Tokyo2020 ####
prior_attend <- dat %>% 
  group_by(athlete) %>% 
  filter(n()>1) %>% 
  pull(athlete)
dat <- dat %>% 
  mutate(prior_attend = ifelse(olympic=="Tokyo2020" & athlete %in% prior_attend, 1, 0))

```

```{r, message=FALSE, warning=FALSE}
#### COVID-19 cases as of July 22, 2021 ####
# COVID-19 cases collected from [Github](https://github.com/CSSEGISandData/COVID-19).
#url <- getURL("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv")

url <- "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"
jhu <- read_csv(url) %>%
  # cases are cumulated so that I kept only "7/22/21", which is the start date of Tokyo2020
  dplyr::select(`Province/State`, `Country/Region`, `7/22/21`) %>% 
  # keep the resion to be consistent with other data
  mutate(`Country/Region2` = ifelse(is.na(`Province/State`), `Country/Region`,
                                    ifelse(`Province/State`=="Hong Kong", "Hong Kong",
                                           `Country/Region`))) %>% 
  group_by(`Country/Region2`) %>% 
  summarise(case_total = sum(`7/22/21`), .groups="drop") %>% 
  rename(country = `Country/Region2`) %>% 
  dplyr::select(country, case_total)

```

```{r, message=FALSE, warning=FALSE}
#### Population and GDP ####

## Population ##
# Read in Johns Hopkins UID lookup table
# Source: https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv
url <- "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv"
pop <- read_csv(url)

## GDP data ##
# Read in GDP data on WORLD BANK
# Source: https://api.worldbank.org/v2/en/indicator/NY.GDP.MKTP.CD?downloadformat=csv
url <- "https://api.worldbank.org/v2/en/indicator/NY.GDP.MKTP.CD?downloadformat=csv"
gdp <- read_csv("API_NY.GDP.MKTP.CD_DS2_en_csv_v2_3263806.csv")

# Join the population and the GDP data
temp <- left_join(pop %>% subset(is.na(Province_State)), 
                  gdp %>% 
                    rename(iso3 = `Country Code`,
                           gdp2016 = `2016`,
                           gdp2017 = `2017`,
                           gdp2018 = `2018`,
                           gdp2019 = `2019`,
                           gdp2020 = `2020`) %>% 
                    dplyr::select(iso3, `Country Name`, gdp2016:gdp2020),
                  by = "iso3") # combine the dataframes according to isco3

```

```{r, message=FALSE, warning=FALSE}
#### Combine the jhu data + (population + GDP)
jhu <- left_join(jhu, 
                 temp %>% rename(country = Country_Region), 
                 # join the dataframes by consistent country names
                 by="country") 

jhu <- jhu %>% 
  # calculate COVID-19 case per population
  mutate(case_pp = case_total/Population) %>% 
  # select only area/country names, case per population and GDP data
  dplyr::select(country, case_pp, gdp2016:gdp2020)

# Reclassify discrepant area/country names
jhu <- jhu %>% 
  mutate(country = ifelse(country %in% dat$country, country, 
                          case_when(country == "Taiwan*" ~ "Taiwan",
                                    country == "Czechia" ~ "Czech Republic",
                                    country == "Democratic Republic of the Congo" ~ "Congo",
                                    country == "United Kingdom" ~ "Great Britain",
                                    country == "Korea, South" ~ "South Korea",
                                    country == "US" ~ "United States")))

```

```{r, message=FALSE, warning=FALSE}
#### join the datasets: dat+(jhu+pop+gdp) ####
# No data on cases: North Korea, Palestine, Pueruto Rico, Refugee Olympic Team
dat <- left_join(dat, jhu, by="country")

```

```{r, message=FALSE, warning=FALSE}
#### Continent ####
# URL of continent category
url <- "https://www.newworldencyclopedia.org/entry/list_of_countries_by_continent"

# Extract all tables in the page
tab <- read_html(url) %>% 
  html_nodes("table") 
# Africa
africa <- tab[[1]] %>% 
  html_table() %>% 
  .[,c(1,3)]
africa <- paste0(africa[,1], africa[,2], "South Sudan") # add discrepant country name
# Asia
asia <- tab[[2]] %>% 
  html_table() %>% 
  .[,c(1,3)]
asia <- paste0(asia[,1], asia[,2], "Taiwan") # add discrepant country name
# Europe
europe <- tab[[3]] %>% 
  html_table() %>% 
  .[,c(1,3)]
europe <- paste0(europe[,1], europe[,2], "Great Britain") # add discrepant country name
# North America
n_america <- tab[[4]] %>% 
  html_table() %>% 
  .[,c(1,3)]
n_america <- paste0(n_america[,1], n_america[,2])
# South America
s_america <- tab[[5]] %>% 
  html_table() %>% 
  .[,c(1,3)]
s_america <- paste0(s_america[,1], s_america[,2])
# Oceania
oceania <- tab[[6]] %>% 
  html_table() %>% 
  .[,c(1,3)]
oceania <- paste0(oceania[,1], oceania[,2])

# add "continent" column according to the continent categories obtained above
dat <- dat %>% 
  mutate(continent = case_when(str_detect(africa, country) ~ "Africa",
                               country=="Congo (Kinshasa)" ~ "Africa", # add discrepant country name
                               str_detect(asia, country) ~ "Asia",
                               str_detect(europe, country) ~ "Europe",
                               str_detect(n_america, country) ~ "North America",
                               str_detect(s_america, country) ~ "South America",
                               str_detect(oceania, country) ~ "Oceania"))

```

```{r, message=FALSE, warning=FALSE}
#### Final data set ####
# time conversion into seconds for analyses
dat <- dat %>% 
  mutate(time_sec = period_to_seconds(time)) %>% 
  select(rank:time, time_sec, sb:last_col())

## Saving the dataframe
write_csv(dat, "data.csv")
#saveRDS(dat, "data.RData")

## Cleaning the environment
rm(list = ls()[!ls()=="dat"])

## Data
dat %>% slice(1:8) %>% knitr::kable()
```

#### Data information
- `rank`: rank at each Olympic game
- `athlete`: athlete names
- `country`: area or country from which the athlete is
- `time`: records at each Olympic game
- `time_sec`: records at each Olympic game in seconds
- `sb`: season best of the athlete; including national record and personal pest
- `dnf`: did not finish; including did not start and disqualified
- `dob`: date of birth
- `age`: age (years) at the time of each Olympic game
- `sex`: sex category
- `olympic`: Olympic game name
- `case_pp`: total case per population of the athlete country as of July 22, 2021 (Start date of Tokyo 2020)
- `gdp2016:2020`: GDP from 2016 to 2020
- `continent`: continent from which the athlete is
- `lockdown`: yes if the country from which the athletes is implemented lockdown
- `prior_attend`: Attendance before Tokyo (athletes at Rio 2016 are all "no")



